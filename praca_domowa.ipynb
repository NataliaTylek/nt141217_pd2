{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Lab7_Zad1\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "rate_df = (spark.readStream\n",
    "           .format(\"rate\")\n",
    "           .option(\"rowsPerSecond\", 5)\n",
    "           .load())\n",
    "\n",
    "events = (rate_df\n",
    "          .withColumn(\"user_id\", expr(\"concat('u', cast(rand()*100 as int))\"))\n",
    "          .withColumn(\"event_type\", expr(\"case when rand() > 0.7 then 'purchase' else 'view' end\"))\n",
    "          .select(\"timestamp\", \"user_id\", \"event_type\"))\n",
    "\n",
    "batch_counter = {\"count\": 0}\n",
    "def process_batch(df, batch_id):\n",
    "    batch_counter[\"count\"] += 1\n",
    "    print(f\"Batch ID: {batch_id}\")\n",
    "    df.show(truncate=False)\n",
    "\n",
    "query = (events.writeStream\n",
    "         .format(\"console\")\n",
    "         .outputMode(\"append\")\n",
    "         .foreachBatch(process_batch)\n",
    "         .trigger(processingTime=\"10 seconds\")\n",
    "         .start())\n",
    "query.awaitTermination()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "purchases = events.filter(col(\"event_type\") == \"purchase\")\n",
    "\n",
    "query = (purchases.writeStream\n",
    "         .format(\"console\")\n",
    "         .outputMode(\"append\")\n",
    "         .foreachBatch(process_batch)\n",
    "         .trigger(processingTime=\"10 seconds\")\n",
    "         .start())\n",
    "query.awaitTermination()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57d24b9eb4654d6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType()),\n",
    "    StructField(\"event_type\", StringType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"product_id\", StringType()),\n",
    "    StructField(\"category\", StringType()),\n",
    "    StructField(\"price\", DoubleType())\n",
    "])\n",
    "\n",
    "stream = (spark.readStream\n",
    "          .schema(schema)\n",
    "          .json(\"stream_data\")) \n",
    "\n",
    "agg = stream.groupBy(\"event_type\").count()\n",
    "\n",
    "query = (agg.writeStream\n",
    "         .outputMode(\"update\")\n",
    "         .format(\"console\")\n",
    "         .foreachBatch(process_batch)\n",
    "         .start())\n",
    "query.awaitTermination()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f5c764066e36f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window\n",
    "\n",
    "windowed = stream.groupBy(window(\"timestamp\", \"5 minutes\"), \"event_type\").count()\n",
    "\n",
    "query = (windowed.writeStream\n",
    "         .outputMode(\"update\")\n",
    "         .format(\"console\")\n",
    "         .foreachBatch(process_batch)\n",
    "         .start())\n",
    "\n",
    "query.awaitTermination() \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd586f58bf212cc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "windowed_watermarked = (stream.withWatermark(\"timestamp\", \"1 minute\")\n",
    "    .groupBy(window(\"timestamp\", \"5 minutes\"), \"event_type\").count())\n",
    "\n",
    "query = (windowed_watermarked.writeStream\n",
    "         .outputMode(\"complete\")\n",
    "         .format(\"console\")\n",
    "         .foreachBatch(process_batch)\n",
    "         .start())\n",
    "query.awaitTermination()\n",
    "query.stop() \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a3dd2632490c856"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = (events.writeStream\n",
    "         .format(\"console\")\n",
    "         .outputMode(\"append\")\n",
    "         .foreachBatch(process_batch)\n",
    "         .trigger(processingTime=\"10 seconds\")\n",
    "         .start())\n",
    "\n",
    "query.awaitTermination()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd19f0ca418a3c04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d11d844b881781c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
